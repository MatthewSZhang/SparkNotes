{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "1. Decision tree classifier\n",
    "2. Decision tree regression <br/>\n",
    "\n",
    "The evaluatiors are \"BinaryClassificationEvaluator\", \"RegressionEvaluator\", and \"MulticlassClassificationEvaluator\". All of them take two inputs (label, and prediction), and one output (metric). The model prediction performance is evluated by the performance indicator (metric). See detail:<br/>\n",
    "Binary:https://spark.apache.org/docs/2.3.0/api/java/org/apache/spark/ml/evaluation/BinaryClassificationEvaluator.html#metricName--\n",
    "Regreesion:https://spark.apache.org/docs/2.3.0/api/java/org/apache/spark/ml/evaluation/RegressionEvaluator.html#metricName--\n",
    "Multiclass:https://spark.apache.org/docs/2.3.0/api/java/org/apache/spark/ml/evaluation/MulticlassClassificationEvaluator.html#metricName--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "import org.apache.spark.ml.linalg.Vectors\n",
       "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\n",
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
       "import org.apache.spark.ml.regression.{DecisionTreeRegressor, DecisionTreeRegressionModel}\n",
       "import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}\n",
       "import org.apache.spark.ml.classification.{DecisionTreeClassifier, DecisionTreeClassificationModel}\n",
       "import org.apache.spark.ml.evaluation.{BinaryClassificationEvaluator, RegressionEvaluator}\n",
       "sparkSession: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@50b1565a\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.regression.{DecisionTreeRegressor, DecisionTreeRegressionModel}\n",
    "import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}\n",
    "import org.apache.spark.ml.classification.{DecisionTreeClassifier, DecisionTreeClassificationModel}\n",
    "import org.apache.spark.ml.evaluation.{BinaryClassificationEvaluator, RegressionEvaluator}\n",
    "\n",
    "val sparkSession = SparkSession.builder.\n",
    "    master(\"local[4]\").\n",
    "    appName(\"Decision Tree\").\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC on the test data is 0.6484120120797818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rawRDD: org.apache.spark.rdd.RDD[String] = files/credit_card_clients.csv MapPartitionsRDD[1] at textFile at <console>:43\n",
       "fileEnd: Int = 30003\n",
       "noHeaderRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[3] at mapPartitions at <console>:45\n",
       "dataRDD: org.apache.spark.rdd.RDD[Array[Double]] = MapPartitionsRDD[8] at repartition at <console>:46\n",
       "dataDF: org.apache.spark.sql.DataFrame = [label: double, features: vector]\n",
       "trainingData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: double, features: vector]\n",
       "testData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: double, features: vector]\n",
       "labelIndexer: org.apache.spark.ml.feature.StringIndexerModel = strIdx_8e203391ea78\n",
       "featureIndexer: org.apache.spark.ml.feature.VectorIndexerModel = vecIdx_009e55388bba\n",
       "dt:..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Read Data\n",
    "val rawRDD = sparkSession.sparkContext.textFile(\"files/credit_card_clients.csv\", 1)\n",
    "val fileEnd = rawRDD.count.toInt // convert long into int for arithmetic operation\n",
    "val noHeaderRDD = rawRDD.mapPartitions(_.take(fileEnd-1)).mapPartitions(_.drop(2)) // remove the last empty line and the first two lines (header)\n",
    "val dataRDD = noHeaderRDD.map(_.replace(\"\\\"\", \"\").split(\",\").map(_.toDouble)).repartition(20)\n",
    "//*dataRDD.partitions.size // check partition size\n",
    "//*dataRDD.groupBy(\"label\").count.show // check the labels\n",
    "val dataDF = dataRDD.map(x => (x(24), Vectors.dense(x.take(24)))).toDF(\"label\", \"features\")\n",
    "val Array(trainingData, testData) = dataDF.randomSplit(Array(0.7, 0.3), seed = 123)\n",
    "\n",
    "// Build pipeline about decision tree classification\n",
    "val labelIndexer = new StringIndexer().\n",
    "  setInputCol(\"label\").\n",
    "  setOutputCol(\"indexedLabel\").\n",
    "  fit(dataDF)\n",
    "\n",
    "val featureIndexer = new VectorIndexer().\n",
    "  setInputCol(\"features\").\n",
    "  setOutputCol(\"indexedFeatures\").\n",
    "  setMaxCategories(10). // features with > 10 distinct values are treated as continuous.\n",
    "  fit(dataDF)\n",
    "\n",
    "val dt = new DecisionTreeClassifier().\n",
    "  setLabelCol(\"indexedLabel\").\n",
    "  setFeaturesCol(\"indexedFeatures\")\n",
    "\n",
    "val labelConverter = new IndexToString().\n",
    "  setInputCol(\"prediction\").\n",
    "  setOutputCol(\"predictedLabel\").\n",
    "  setLabels(labelIndexer.labels)\n",
    "\n",
    "val pipeline = new Pipeline().\n",
    "  setStages(Array(labelIndexer, featureIndexer, dt, labelConverter))\n",
    "\n",
    "// Cross validation\n",
    "val paramGrid = new ParamGridBuilder().\n",
    "  addGrid(dt.maxBins, Array(16, 32, 64)).\n",
    "  addGrid(dt.maxDepth, Array(5, 7, 9)).\n",
    "  addGrid(dt.impurity, Array(\"gini\", \"entropy\")).\n",
    "  build()\n",
    "\n",
    "val cv = new CrossValidator().\n",
    "  setEstimator(pipeline).\n",
    "  setEvaluator(new BinaryClassificationEvaluator).\n",
    "  setEstimatorParamMaps(paramGrid).\n",
    "  setNumFolds(5)  // Use 3+ in practice\n",
    "\n",
    "val cvModel = cv.fit(trainingData)\n",
    "\n",
    "// Evaluation\n",
    "val evaluator = new BinaryClassificationEvaluator().\n",
    "    setLabelCol(\"indexedLabel\").\n",
    "    setRawPredictionCol(\"prediction\").\n",
    "    setMetricName(\"areaUnderROC\")\n",
    "\n",
    "val predictions = cvModel.transform(testData)\n",
    "val roc = evaluator.evaluate(predictions)\n",
    "println(\"The ROC on the test data is \" + roc)\n",
    "\n",
    "// Check the model property\n",
    "val bestDTM = cvModel.bestModel.asInstanceOf[PipelineModel].stages(2).asInstanceOf[DecisionTreeClassificationModel]\n",
    "//*bestDTM.getImpurity\n",
    "//*bestDTM.getMaxBins\n",
    "//*bestDTM.getMaxDepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the test data is 0.7285336650923595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rawRDD: org.apache.spark.rdd.RDD[String] = files/winequality-white.csv MapPartitionsRDD[4899] at textFile at <console>:61\n",
       "noHeaderRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[4900] at mapPartitions at <console>:62\n",
       "dataRDD: org.apache.spark.rdd.RDD[Array[Double]] = MapPartitionsRDD[4905] at repartition at <console>:63\n",
       "dataDF: org.apache.spark.sql.DataFrame = [label: double, features: vector]\n",
       "trainingData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: double, features: vector]\n",
       "testData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: double, features: vector]\n",
       "featureIndexer: org.apache.spark.ml.feature.VectorIndexerModel = vecIdx_a6bd7a8e7f61\n",
       "dt: org.apache.spark.ml.regression.DecisionTreeRegressor = dtr_ad4c21322509\n",
       "pipeline: org.apache.spa..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Read data\n",
    "val rawRDD = sparkSession.sparkContext.textFile(\"files/winequality-white.csv\", 1)\n",
    "val noHeaderRDD = rawRDD.mapPartitions(_.drop(1)) // remove first line (header)\n",
    "val dataRDD = noHeaderRDD.map(_.split(\";\").map(_.toDouble)).repartition(20)\n",
    "//*dataRDD.partitions.size // check partition size\n",
    "//*dataRDD.groupBy(\"label\").count.show // check the labels\n",
    "val dataDF = dataRDD.map(x => (x(11), Vectors.dense(x.take(11)))).toDF(\"label\", \"features\")\n",
    "val Array(trainingData, testData) = dataDF.randomSplit(Array(0.7, 0.3), seed = 123)\n",
    "\n",
    "// Build pipeline about decision tree regression\n",
    "val featureIndexer = new VectorIndexer().\n",
    "  setInputCol(\"features\").\n",
    "  setOutputCol(\"indexedFeatures\").\n",
    "  setMaxCategories(4). //we treat features with > 4 distinct values as continuous.\n",
    "  fit(dataDF)\n",
    "\n",
    "val dt = new DecisionTreeRegressor().\n",
    "  setLabelCol(\"label\").\n",
    "  setFeaturesCol(\"indexedFeatures\")\n",
    "\n",
    "val pipeline = new Pipeline().\n",
    "  setStages(Array(featureIndexer, dt))\n",
    "\n",
    "// Cross validation\n",
    "val paramGrid = new ParamGridBuilder().\n",
    "  addGrid(dt.maxBins, Array(10, 15, 20)).\n",
    "  addGrid(dt.maxDepth, Array(5, 7, 9)).\n",
    "  build()\n",
    "\n",
    "val cv = new CrossValidator().\n",
    "  setEstimator(pipeline).\n",
    "  setEvaluator(new RegressionEvaluator).\n",
    "  setEstimatorParamMaps(paramGrid).\n",
    "  setNumFolds(5)  // Use 3+ in practice\n",
    "\n",
    "val cvModel = cv.fit(trainingData)\n",
    "\n",
    "// Evaluation\n",
    "val evaluator = new RegressionEvaluator().\n",
    "    setLabelCol(\"label\").\n",
    "    setPredictionCol(\"prediction\").\n",
    "    setMetricName(\"rmse\")\n",
    "\n",
    "val predictions = cvModel.transform(testData)\n",
    "val rmse = evaluator.evaluate(predictions)\n",
    "println(\"The RMSE on the test data is \" + rmse)\n",
    "\n",
    "// Check the model property\n",
    "val bestDTM = cvModel.bestModel.asInstanceOf[PipelineModel].stages(1).asInstanceOf[DecisionTreeRegressionModel]\n",
    "//*bestDTM.getImpurity\n",
    "//*bestDTM.getMaxBins\n",
    "//*bestDTM.getMaxDepth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
